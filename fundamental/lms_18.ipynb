{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bulgarian-force",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sufficient-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "seeing-operator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-terminal",
   "metadata": {},
   "source": [
    "###  Sequential AIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dressed-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential model\n",
    "\n",
    "model = keras.Sequential([\n",
    "    #32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "    keras.layers.Conv2D(32, 3, activation = 'relu'),\n",
    "    #64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "    keras.layers.Conv2D(64, 3, activation = 'relu'),\n",
    "    #Flatten 레이어\n",
    "    keras.layers.Flatten(),\n",
    "    #128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    #데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "equipped-continuity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 30s 14ms/step - loss: 0.2294 - accuracy: 0.9314\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0348 - accuracy: 0.9898\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0176 - accuracy: 0.9945\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0101 - accuracy: 0.9969\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0084 - accuracy: 0.9974\n",
      "313/313 - 2s - loss: 0.0528 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0528082475066185, 0.987500011920929]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', \n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs = 5)\n",
    "model.evaluate(x_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-offering",
   "metadata": {},
   "source": [
    "### Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "elementary-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alien-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "raised-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = (28, 28, 1))\n",
    "\n",
    "x = keras.layers.Conv2D(32, 3, activation = 'relu')(inputs)\n",
    "x = keras.layers.Conv2D(64, 3, activation = 'relu')(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(128, activation = 'relu')(x)\n",
    "\n",
    "predictions = keras.layers.Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs = inputs, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "american-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2162 - accuracy: 0.9304\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0312 - accuracy: 0.9904\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0202 - accuracy: 0.9936\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0108 - accuracy: 0.9964\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0091 - accuracy: 0.9970\n",
      "313/313 - 1s - loss: 0.0669 - accuracy: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06688259541988373, 0.9853000044822693]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-monster",
   "metadata": {},
   "source": [
    "### Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "offensive-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "typical-probability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "arabic-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.Model 을 상속받았으며, __init__()와 call() 메소드를 가진 모델 클래스\n",
    "#32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "#64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "#Flatten 레이어\n",
    "#128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "#데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "#call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
    "\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "furnished-assumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2112 - accuracy: 0.9338\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0328 - accuracy: 0.9891\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0181 - accuracy: 0.9940\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0099 - accuracy: 0.9967\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0090 - accuracy: 0.9967\n",
      "313/313 - 2s - loss: 0.0448 - accuracy: 0.9878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.044782355427742004, 0.9878000020980835]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-accessory",
   "metadata": {},
   "source": [
    "## CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-conducting",
   "metadata": {},
   "source": [
    "### Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "mediterranean-couple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alpha-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "#pool_size가 2인 MaxPool 레이어\n",
    "#32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "#pool_size가 2인 MaxPool 레이어\n",
    "#256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "#데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pleasant-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 3.9845 - accuracy: 0.1005\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.9390 - accuracy: 0.2753\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.5908 - accuracy: 0.3500\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3578 - accuracy: 0.3928\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.1603 - accuracy: 0.4366\n",
      "313/313 - 1s - loss: 2.5754 - accuracy: 0.3621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.575407028198242, 0.3621000051498413]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-heath",
   "metadata": {},
   "source": [
    "### Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "searching-breed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "lasting-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(inputs)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mighty-punishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 4.0243 - accuracy: 0.0925\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.0257 - accuracy: 0.2560\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.7087 - accuracy: 0.3234\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.4927 - accuracy: 0.3657\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3248 - accuracy: 0.4032\n",
      "313/313 - 1s - loss: 2.6579 - accuracy: 0.3401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6578991413116455, 0.3400999903678894]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-command",
   "metadata": {},
   "source": [
    "### Subclassing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "nonprofit-symbol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "settled-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.Model 을 상속받았으며, __init__()와 call() 메소드를 가진 모델 클래스\n",
    "#16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "#pool_size가 2인 MaxPool 레이어\n",
    "#32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "#pool_size가 2인 MaxPool 레이어\n",
    "#256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "#데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "#call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "mature-criterion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 4.0185 - accuracy: 0.0926\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.0128 - accuracy: 0.2621\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.6994 - accuracy: 0.3250\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.4714 - accuracy: 0.3723\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.2796 - accuracy: 0.4123\n",
      "313/313 - 1s - loss: 2.6349 - accuracy: 0.3413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.634915828704834, 0.34130001068115234]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-government",
   "metadata": {},
   "source": [
    "## GradientTape\n",
    "- Tensorflow에서 제공하는 tf.GradientTape는 위와 같이 순전파(forward pass) 로 진행된 모든 연산의 중간 레이어값을 tape에 기록\n",
    "- 이를 이용해 gradient를 계산한 후 tape를 폐기하는 기능을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "informed-passport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 모델 구성부분\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "forward-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# tf.GradientTape()를 활용한 train_step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-assembly",
   "metadata": {},
   "source": [
    "- tape.gradient()를 통해 매 스텝 학습이 진행될 때마다 발생하는 그래디언트를 추출한 후 optimizer.apply_gradients()를 통해 발생한 그래디언트가 업데이트해야 할 파라미터 model.trainable_variables를 지정해 주는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "higher-diary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: last batch loss = 4.6011\n",
      "Epoch 1: last batch loss = 4.3902\n",
      "Epoch 2: last batch loss = 4.4476\n",
      "Epoch 3: last batch loss = 4.2276\n",
      "Epoch 4: last batch loss = 2.9324\n",
      "It took 103.44991827011108 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def train_model(batch_size=32):\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "            if step % batch_size == batch_size-1:\n",
    "                x_batch.append(x)\n",
    "                y_batch.append(y)\n",
    "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-crossing",
   "metadata": {},
   "source": [
    "- train_model() 메소드가 실은 우리가 그동안 사용했던 model.fit() 메소드와 기능적으로 같은 것을 알 수 있음.\n",
    "\n",
    "- tf.GradientTape()를 활용하면 model.compile()과 model.fit() 안에 감추어져 있던 한 스텝의 학습 단계(위 예제에서는 train_step 메소드)를 끄집어내서 자유롭게 재구성할 수 있게 됨.\n",
    "- 지도학습 방식과 다른 강화학습 또는 GAN(Generative Advasarial Network)의 학습을 위해서는 train_step 메소드의 재구성이 필수적이므로 tf.GradientTape()의 활용법을 꼭 숙지해 두어야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "binary-celebration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0459"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp/len(y_test)  # Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-fireplace",
   "metadata": {},
   "source": [
    "- 그래디언트를 활용할 필요가 없는 evaluation 단계는 기존 model.predict() 메소드를 다시 활용\n",
    "- 충분한 성능을 확인할 수 있을 만큼의 학습이 진행된 상태가 아니니 최종 Accuracy 값은 신경 쓰지 않아도 무방"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-agent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
